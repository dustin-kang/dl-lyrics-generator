{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[P403]data_preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPj19d4iCRO6LJeuvoRD9F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dustin-kang/Proj4_LyricsGenerator/blob/main/Note/%5BP403%5Ddata_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠 데이터 전처리\n",
        "- 크롤링한 데이터를 분석하는 작업이다.\n",
        "- 추가적인 시각화도 한다."
      ],
      "metadata": {
        "id": "OOV1vYvy4gA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. P402 사전 작업"
      ],
      "metadata": {
        "id": "-ym7IBHx42AG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rigr7_m43pbT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "# 시각화 도구 #\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image # 편지지 시각화\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator \n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# warnings #\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2VSsIY54rTA",
        "outputId": "0b9213c1-5fe9-45db-eaa0-e4051863a7af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/AI07/proj/vibe_j.csv')\n",
        "nltk.download('punkt')\n",
        "df['chars'] = df['lyrics'].apply(len)\n",
        "df['words'] = df.apply(lambda row: nltk.word_tokenize(row['lyrics']), axis=1).apply(len)\n",
        "df['lines'] = df['lyrics'].str.split('\\n').apply(len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPuQ-7go4nJb",
        "outputId": "ed48321c-699a-4e41-ed38-493a9529844a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 말뭉치(Corpus) 생성 및 데이터 전처리"
      ],
      "metadata": {
        "id": "72cXLKsR49i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ''\n",
        "\n",
        "for doc in df.lyrics:\n",
        "  corpus += doc # 곡 당 가사들을 corpus 문자열에 넣는다.\n",
        "\n",
        "corpus = corpus.lower()\n",
        "\n",
        "print(\"유니크한 철자의 수:\", len(set(corpus)))\n",
        "print(\"유니크한 철자:\",sorted(set(corpus)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK7g7nXX5OZr",
        "outputId": "a77e8e24-19eb-49e2-fc6d-366ec1cd54c2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유니크한 철자의 수: 511\n",
            "유니크한 철자: ['\\n', ' ', '!', '\"', '$', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', '\\\\', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '¡', '´', '¾', '¿', 'à', 'á', 'å', 'æ', 'é', 'ê', 'í', 'î', 'ñ', 'ó', 'ø', 'ú', 'е', '\\u2005', '\\u200a', '–', '—', '‘', '’', '‚', '“', '”', '…', '′', '″', '※', '\\u205f', '가', '각', '간', '갈', '감', '갑', '갖', '같', '개', '객', '거', '걱', '건', '걸', '것', '게', '겐', '겠', '겨', '결', '겹', '곁', '계', '고', '곡', '곧', '곳', '공', '과', '관', '괜', '괴', '교', '구', '국', '군', '굴', '궁', '귀', '그', '극', '근', '금', '기', '긴', '길', '깊', '까', '깐', '깨', '꺼', '껏', '께', '꽃', '꾸', '꿈', '끊', '끝', '끼', '낄', '나', '난', '날', '남', '났', '낯', '내', '냐', '너', '넌', '널', '네', '녀', '녕', '노', '놀', '놈', '놓', '누', '눈', '눌', '느', '는', '늘', '니', '닌', '닐', '다', '닥', '단', '닫', '달', '당', '대', '더', '덕', '던', '도', '돌', '동', '돼', '되', '된', '될', '두', '둔', '둘', '둠', '뒤', '드', '든', '듣', '들', '듯', '디', '따', '때', '땐', '땠', '떠', '떤', '떨', '떻', '또', '라', '란', '랄', '람', '랍', '랏', '랐', '랑', '래', '랜', '러', '런', '럼', '럽', '렇', '레', '려', '력', '렸', '로', '롭', '루', '르', '른', '를', '름', '리', '린', '릴', '림', '마', '막', '만', '많', '말', '맑', '맘', '망', '맞', '매', '맺', '머', '멀', '멈', '며', '면', '명', '모', '목', '몰', '못', '몽', '무', '문', '물', '뭉', '뭔', '미', '밀', '밑', '바', '박', '밖', '반', '받', '발', '밝', '밟', '밤', '방', '백', '버', '번', '벌', '법', '벽', '변', '별', '보', '복', '봐', '부', '분', '불', '비', '빈', '빛', '빠', '빨', '뿌', '뿐', '쁨', '사', '살', '상', '새', '색', '생', '서', '선', '성', '세', '센', '소', '속', '손', '수', '순', '술', '숨', '슈', '스', '슨', '슬', '습', '시', '식', '신', '실', '싫', '심', '싱', '싶', '싸', '쌓', '썼', '쓸', '씀', '씁', '아', '안', '않', '알', '았', '앞', '애', '액', '야', '얀', '얘', '어', '억', '언', '얻', '얼', '없', '엇', '었', '에', '엔', '여', '연', '열', '염', '였', '영', '예', '오', '온', '올', '와', '완', '왜', '외', '요', '용', '우', '운', '울', '움', '웃', '워', '원', '웠', '위', '유', '으', '은', '을', '음', '의', '이', '인', '일', '잃', '입', '있', '잊', '자', '작', '잖', '잘', '잠', '잡', '장', '저', '적', '전', '절', '젊', '정', '제', '젠', '져', '졌', '조', '종', '좋', '죠', '주', '준', '줄', '줍', '중', '줘', '줬', '쥐', '즘', '지', '직', '진', '질', '집', '짓', '쨌', '쩔', '찍', '차', '착', '찬', '찮', '찾', '채', '처', '천', '청', '초', '최', '추', '축', '춘', '출', '춰', '치', '친', '칠', '침', '캘', '케', '켜', '코', '콤', '큼', '타', '태', '터', '테', '통', '트', '특', '틀', '파', '판', '팔', '평', '포', '표', '푸', '풍', '픔', '필', '하', '한', '할', '함', '합', '항', '해', '햇', '했', '행', '향', '허', '헤', '혀', '현', '혼', '화', '활', '회', '후', '휘', '흐', '희', '히', '\\ufeff']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "corpus = re.sub(\"[^A-Za-z0-9'\\.\\n]\",\" \",corpus)"
      ],
      "metadata": {
        "id": "w5H6BWqN48ot"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"유니크한 철자:\",sorted(set(corpus)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieDeK41n5PXx",
        "outputId": "a5e260f7-141b-4054-b38c-0b6f4f486edc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유니크한 철자: ['\\n', ' ', \"'\", '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 고유 문자 목록 만들기"
      ],
      "metadata": {
        "id": "01IUnDM67wMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 딕셔너리를 매핑하기 위해 말뭉치에 있는 모든 Unique_char(고유문자)을 저장한다.\n",
        "unique_char = sorted(list(set(corpus)))\n",
        "\n",
        "corpus_len = len(corpus)\n",
        "unique_len = len(unique_char)\n",
        "\n",
        "# 어휘에 접근할 딕셔너리를 만든다. -> unique_char과 매핑\n",
        "mapping = dict((c, i) for i, c in enumerate(unique_char))\n",
        "re_mapping = dict((i, c) for i, c in enumerate(unique_char)) # 역(반대)\n",
        "\n",
        "print(\"문자열 철자의 총 갯수:\", corpus_len)\n",
        "print(\"고유문자(unique_len)의 갯수:\", unique_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoxInQq27Yj0",
        "outputId": "d61a73ff-520c-40f8-e86a-bfdb01514e89"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자열 철자의 총 갯수: 3846836\n",
            "고유문자(unique_len)의 갯수: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코퍼스 분할\n",
        "length = 40\n",
        "features = []\n",
        "targets = []\n",
        "\n",
        "for i in range(0, corpus_len - length):\n",
        "    feature = corpus[i:i + length]\n",
        "    target = corpus[i + length]\n",
        "    features.append([mapping[j] for j in feature])\n",
        "    targets.append(mapping[target])\n",
        "\n",
        "target_len = len(targets)\n",
        "print(\"말뭉치 내 시퀀수의 총합:\", target_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtlecwWL8rI7",
        "outputId": "2ffeea2f-753a-40aa-8040-d7990a92073e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "말뭉치 내 시퀀수의 총합: 3846796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Features 와 Target 데이터 만들기"
      ],
      "metadata": {
        "id": "qhGXRnyk__U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "# Features로 Reshape 후 고유문자로 정규화 진행\n",
        "X = (np.reshape(features, (target_len, length, 1)))/ float(unique_len)\n",
        "\n",
        "# Target값 원핫 인코딩\n",
        "## keras.utils.np_utils 패키지에 있는 to_categorical 함수는 바로 One-hot 인코딩을 해주는 함수입니다.\n",
        "y = np_utils.to_categorical(targets)"
      ],
      "metadata": {
        "id": "yguw5zOX9l_b"
      },
      "execution_count": 54,
      "outputs": []
    }
  ]
}